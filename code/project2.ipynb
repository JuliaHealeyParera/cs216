{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "web scraper using beautiful soup to get the table from teamrankings.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from away_winLoss.html has been saved to away_winLoss.csv\n",
      "No table found in all_bbalcolleges.html\n",
      "Data from overallWinPercentage.html has been saved to overallWinPercentage.csv\n",
      "Data from asUnderdog_winLoss.html has been saved to asUnderdog_winLoss.csv\n",
      "Data from equalRest_winLoss.html has been saved to equalRest_winLoss.csv\n",
      "Data from afterLoss_winLoss.html has been saved to afterLoss_winLoss.csv\n",
      "Data from restAdvantage_winLoss.html has been saved to restAdvantage_winLoss.csv\n",
      "Data from home_winLoss.html has been saved to home_winLoss.csv\n",
      "Data from neutralSite_winLoss.html has been saved to neutralSite_winLoss.csv\n",
      "Data from afterWin_winLoss.html has been saved to afterWin_winLoss.csv\n",
      "All files processed.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Directory where your HTML files are stored\n",
    "directory_path = '../data/html_teamranking/'\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith(\".html\"):\n",
    "        # Construct full file path\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        # Open and parse each HTML file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            soup = BeautifulSoup(file, 'html.parser')\n",
    "        \n",
    "        # Locate the table\n",
    "        table = soup.find('table')\n",
    "        if not table:\n",
    "            print(f\"No table found in {filename}\")\n",
    "            continue  # Skip to next file if no table found\n",
    "\n",
    "        # Extract headers\n",
    "        headers = [header.text.strip() for header in table.find_all('th')]\n",
    "\n",
    "        # Extract rows\n",
    "        rows = []\n",
    "        for row in table.find_all('tr'):\n",
    "            cells = row.find_all('td')\n",
    "            row_data = [cell.text.strip() for cell in cells]\n",
    "            if row_data:\n",
    "                rows.append(row_data)\n",
    "        \n",
    "        # Save data to a new CSV file\n",
    "        csv_filename = filename.replace('.html', '.csv')\n",
    "        csv_path = os.path.join(directory_path, csv_filename)\n",
    "        \n",
    "        with open(csv_path, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(headers)  # Write headers\n",
    "            writer.writerows(rows)    # Write data rows\n",
    "        print(f\"Data from {filename} has been saved to {csv_filename}\")\n",
    "\n",
    "print(\"All files processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame created for afterLoss_winLoss.csv\n",
      "DataFrame created for asUnderdog_winLoss.csv\n",
      "DataFrame created for restAdvantage_winLoss.csv\n",
      "DataFrame created for overallWinPercentage.csv\n",
      "DataFrame created for neutralSite_winLoss.csv\n",
      "DataFrame created for equalRest_winLoss.csv\n",
      "DataFrame created for away_winLoss.csv\n",
      "DataFrame created for afterWin_winLoss.csv\n",
      "DataFrame created for home_winLoss.csv\n",
      "DataFrame created for Sport_Data_2003_2004_2005_2006_2007_2008_2009_2010_2011_2012_2013_2014_2015_2016_2017_2018_2019_2020_2021_2022\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#initializing so there's no yellow lines lol\n",
    "afterLoss_winLoss = 0\n",
    "afterWin_winLoss = 0\n",
    "asUnderdog_winLoss = 0\n",
    "restAdvantage_winLoss = 0\n",
    "equalRest_winLoss = 0\n",
    "away_winLoss = 0\n",
    "home_winLoss = 0\n",
    "neutralSite_winLoss = 0\n",
    "overallWinPercentage=0\n",
    "\n",
    "# Directory where your CSV files are stored\n",
    "directory_path = '../data/html_teamranking/'\n",
    "\n",
    "# Loop through each CSV file in the directory and create DataFrames\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        # Construct full file path\n",
    "        csv_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        # Read CSV into a DataFrame\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Use filename as the name of the DataFrame (without \".csv\")\n",
    "        exec(f\"{filename.replace('.csv', '')} = df\")\n",
    "        \n",
    "        # Print to confirm\n",
    "        print(f\"DataFrame created for {filename}\")\n",
    "\n",
    "team_expenses = pd.read_csv(\"../data/Sport_Data_2003_2004_2005_2006_2007_2008_2009_2010_2011_2012_2013_2014_2015_2016_2017_2018_2019_2020_2021_2022.csv\")\n",
    "\n",
    "team_expenses.head()\n",
    "\n",
    "print(f\"DataFrame created for Sport_Data_2003_2004_2005_2006_2007_2008_2009_2010_2011_2012_2013_2014_2015_2016_2017_2018_2019_2020_2021_2022\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------these datasets range from the 2003-2004 season to 2024-2025 season (current)\n",
    "\n",
    "#previous game was a loss -> is the next game a win/loss?\n",
    "afterLoss_winLoss\n",
    "\n",
    "#previous game was a win -> is the next game a win/loss?\n",
    "afterWin_winLoss\n",
    "\n",
    "#games won/lost as the underdog aka lower team ranking/seeding\n",
    "asUnderdog_winLoss\n",
    "\n",
    "#games won/lost WITH a rest advantage, or having 1+ days of rest compared to the other team\n",
    "restAdvantage_winLoss\n",
    "\n",
    "#games won/lost with equal days rest compared to the other team (baseline for restAdvantange)\n",
    "equalRest_winLoss\n",
    "\n",
    "#games won/lost as the away team\n",
    "away_winLoss\n",
    "\n",
    "#games won/lost as the home team\n",
    "home_winLoss\n",
    "\n",
    "#games won/lost playing on a neutral site (might be useful to compare as baseline agasint home/away)\n",
    "neutralSite_winLoss\n",
    "\n",
    "#total wins and losses of every game\n",
    "overallWinPercentage\n",
    "\n",
    "#total team expenses \n",
    "bball_expenses = team_expenses[[\"Survey Year\", \"UNITID\", \"OPE ID\", \"Institution Name\", \"State CD\", \"Expenses Men's Team\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/angiehuang/mambaforge/bin/python\n",
      "Requirement already satisfied: python-Levenshtein in /Users/angiehuang/mambaforge/lib/python3.10/site-packages (0.26.1)\n",
      "Requirement already satisfied: Levenshtein==0.26.1 in /Users/angiehuang/mambaforge/lib/python3.10/site-packages (from python-Levenshtein) (0.26.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /Users/angiehuang/mambaforge/lib/python3.10/site-packages (from Levenshtein==0.26.1->python-Levenshtein) (3.10.1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "!{sys.executable} -m pip install python-Levenshtein\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "def custom_score(str1, str2):\n",
    "    \"\"\"\n",
    "    Custom scoring function that penalizes missing words less.\n",
    "    Uses fuzz.partial_ratio for lenient matching, with extra weight for fewer missing words.\n",
    "    \"\"\"\n",
    "    # First get the basic partial match score\n",
    "    partial_score = fuzz.partial_ratio(str1, str2)\n",
    "    \n",
    "    # Adjust the score based on the length of the two strings (i.e., fewer words missing is better)\n",
    "    word_diff_penalty = abs(len(str1.split()) - len(str2.split()))\n",
    "    \n",
    "    # Optionally, add a small penalty for missing words\n",
    "    adjusted_score = partial_score - (word_diff_penalty * 2)  # Adjust the factor for leniency\n",
    "    \n",
    "    # Ensure the score stays within 0-100\n",
    "    return max(min(adjusted_score, 100), 0)\n",
    "\n",
    "def find_best_match_between_dfs(df1, column1, df2, column2, threshold=50):\n",
    "    \"\"\"\n",
    "    Finds the best fuzzy match for each item in `column1` from `df1` within the entire `column2` from `df2`.\n",
    "    Returns a new DataFrame with original names, best matches, and scores using custom scoring for partial matching.\n",
    "    \"\"\"\n",
    "    matches = []\n",
    "    \n",
    "    for item in df1[column1]:\n",
    "        # Extract the best match and custom score\n",
    "        match_data = process.extractOne(item, df2[column2], scorer=lambda str1, str2: custom_score(str1, str2))\n",
    "        if match_data:\n",
    "            best_match = match_data[0]  # Best match string\n",
    "            score = match_data[1]       # Similarity score\n",
    "        else:\n",
    "            best_match = None\n",
    "            score = None\n",
    "        \n",
    "        # Append results if they meet the threshold\n",
    "        matches.append({\n",
    "            column1: item,\n",
    "            f'Best_Match_in_{column2}': best_match if score and score >= threshold else None,\n",
    "            f'Match_Score_in_{column2}': score if score and score >= threshold else None\n",
    "        })\n",
    "    \n",
    "    # Create and return a new DataFrame with matches and scores\n",
    "    return pd.DataFrame(matches)\n",
    "\n",
    "result_df = find_best_match_between_dfs(bball_expenses, 'Institution Name', afterLoss_winLoss, 'Team')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Institution Name Best_Match_in_Team  \\\n",
      "0            Abilene Christian University      Hsn Christian   \n",
      "1                Alabama A & M University            Alabama   \n",
      "2                Alabama State University         Alabama St   \n",
      "3                 Alcorn State University          Alcorn St   \n",
      "4                     American University           American   \n",
      "...                                   ...                ...   \n",
      "6970                  Winthrop University           Winthrop   \n",
      "6971  Wright State University-Main Campus          Wright St   \n",
      "6972                    Xavier University             Xavier   \n",
      "6973                      Yale University               Yale   \n",
      "6974          Youngstown State University           NC State   \n",
      "\n",
      "      Match_Score_in_Team  \n",
      "0                      83  \n",
      "1                      94  \n",
      "2                      98  \n",
      "3                      98  \n",
      "4                      98  \n",
      "...                   ...  \n",
      "6970                   98  \n",
      "6971                   94  \n",
      "6972                   98  \n",
      "6973                   98  \n",
      "6974                   86  \n",
      "\n",
      "[6975 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(result_df)\n",
    "team_names = result_df\n",
    "\n",
    "#this team_names dataset is relating the \"Institution Name\" from the ball_expenses dataframe to the \n",
    "# teamranking ones ie afterLoss_winLoss \"Team\" names\n",
    "\n",
    "#---------------THIS TEAM_NAMES IS ALSO NOT PERFECT SO THERE ARE WRONG RELATIONS AND THINGS BC I AUTOMATED, PLEASE HELP CHECK AND EDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {\n",
    "    \"afterLoss_winLoss\": afterLoss_winLoss,\n",
    "    \"afterWin_winLoss\": afterWin_winLoss,\n",
    "    \"asUnderdog_winLoss\": asUnderdog_winLoss,\n",
    "    \"restAdvantage_winLoss\": restAdvantage_winLoss,\n",
    "    \"equalRest_winLoss\": equalRest_winLoss,\n",
    "    \"away_winLoss\": away_winLoss,\n",
    "    \"home_winLoss\": home_winLoss,\n",
    "    \"neutralSite_winLoss\": neutralSite_winLoss,\n",
    "    \"overallWinPercentage\": overallWinPercentage\n",
    "}\n",
    "\n",
    "# Rename the win percentage column for each DataFrame\n",
    "for name, df in dfs.items():\n",
    "    # Replace 'Win %' with the formatted name, e.g., 'afterLoss_winLoss_win_percent'\n",
    "    df.rename(columns={\"Win %\": f\"{name}_Win_percent\"}, inplace=True)\n",
    "    df.rename(columns={\"MOV\": f\"{name}_MOV\"}, inplace=True)\n",
    "    df.rename(columns={\"ATS +/-\": f\"{name}_ATS\"}, inplace=True)\n",
    "    df.drop('Win-Loss Record', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge win % datasets\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "merged_win_loss_stats = reduce(lambda left, right: pd.merge(left, right, on=\"Team\", how=\"outer\"), dfs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Team afterLoss_winLoss_Win_percent afterWin_winLoss_Win_percent  \\\n",
      "0      AR Lit Rock                         49.1%                        50.0%   \n",
      "1    Abl Christian                         48.0%                        57.2%   \n",
      "2        Air Force                         38.6%                        48.9%   \n",
      "3            Akron                         63.8%                        63.1%   \n",
      "4         Alab A&M                         35.1%                        43.8%   \n",
      "..             ...                           ...                          ...   \n",
      "359      Wright St                         54.4%                        58.0%   \n",
      "360        Wyoming                         50.0%                        53.0%   \n",
      "361         Xavier                         66.8%                        67.9%   \n",
      "362           Yale                         51.1%                        57.5%   \n",
      "363      Youngs St                         40.4%                        45.5%   \n",
      "\n",
      "    asUnderdog_winLoss_Win_percent restAdvantage_winLoss_Win_percent  \\\n",
      "0                            27.6%                             56.8%   \n",
      "1                            25.6%                             66.4%   \n",
      "2                            21.1%                             52.7%   \n",
      "3                            28.2%                             69.8%   \n",
      "4                            19.8%                             39.8%   \n",
      "..                             ...                               ...   \n",
      "359                          31.7%                             61.9%   \n",
      "360                          25.7%                             64.1%   \n",
      "361                          38.5%                             73.2%   \n",
      "362                          28.3%                             48.2%   \n",
      "363                          20.4%                             50.9%   \n",
      "\n",
      "    equalRest_winLoss_Win_percent away_winLoss_Win_percent  \\\n",
      "0                           50.5%                    32.2%   \n",
      "1                           47.3%                    32.7%   \n",
      "2                           38.3%                    22.9%   \n",
      "3                           60.8%                    44.3%   \n",
      "4                           40.9%                    21.8%   \n",
      "..                            ...                      ...   \n",
      "359                         55.3%                    38.7%   \n",
      "360                         46.5%                    29.8%   \n",
      "361                         66.7%                    50.8%   \n",
      "362                         58.2%                    40.7%   \n",
      "363                         40.1%                    26.4%   \n",
      "\n",
      "    home_winLoss_Win_percent neutralSite_winLoss_Win_percent  \\\n",
      "0                      66.4%                           51.5%   \n",
      "1                      71.4%                           63.2%   \n",
      "2                      61.1%                           44.0%   \n",
      "3                      82.3%                           54.5%   \n",
      "4                      59.5%                           32.6%   \n",
      "..                       ...                             ...   \n",
      "359                    73.5%                           50.8%   \n",
      "360                    71.7%                           41.6%   \n",
      "361                    84.8%                           57.4%   \n",
      "362                    71.0%                           57.6%   \n",
      "363                    59.3%                           42.2%   \n",
      "\n",
      "    overallWinPercentage_Win_percent  \n",
      "0                              50.1%  \n",
      "1                              53.7%  \n",
      "2                              44.1%  \n",
      "3                              63.3%  \n",
      "4                              38.2%  \n",
      "..                               ...  \n",
      "359                            56.4%  \n",
      "360                            52.7%  \n",
      "361                            68.6%  \n",
      "362                            54.4%  \n",
      "363                            42.7%  \n",
      "\n",
      "[364 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame that only includes the columns with 'Win_percent' in their name\n",
    "win_percent_columns = [col for col in merged_win_loss_stats.columns if 'Win_percent' in col]\n",
    "\n",
    "win_percent_df = merged_win_loss_stats[['Team'] + win_percent_columns]\n",
    "print(win_percent_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'win_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m csvfile:\n\u001b[1;32m      9\u001b[0m     writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mwriter(csvfile)\n\u001b[0;32m---> 10\u001b[0m     writer\u001b[38;5;241m.\u001b[39mwriterows(win_)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNew data appended to CSV file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'win_' is not defined"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Data to append\n",
    "\n",
    "file_path = '../data/winpercents.csv'\n",
    "\n",
    "# Append data to CSV file\n",
    "with open(file_path, 'a', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(win_)\n",
    "\n",
    "print(f'New data appended to CSV file {file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Survey Year  UNITID  OPE ID     Institution Name State CD  \\\n",
      "6625         2022  222178  353700     AbileneChristian       TX   \n",
      "6626         2022  100654  100200           AlabamaA&M       AL   \n",
      "6627         2022  100724  100500            AlabamaSt       AL   \n",
      "6628         2022  175342  239600             AlcornSt       MS   \n",
      "6629         2022  131159  143400             American       DC   \n",
      "...           ...     ...     ...                  ...      ...   \n",
      "6970         2022  218964  345600             Winthrop       SC   \n",
      "6971         2022  206604  307800  WrightSt-MainCampus       OH   \n",
      "6972         2022  206622  314400               Xavier       OH   \n",
      "6973         2022  130794  142600                 Yale       CT   \n",
      "6974         2022  206695  314500         YoungstownSt       OH   \n",
      "\n",
      "      Expenses Men's Team  \n",
      "6625            2322034.0  \n",
      "6626            1196804.0  \n",
      "6627            1068356.0  \n",
      "6628             749038.0  \n",
      "6629            2656602.0  \n",
      "...                   ...  \n",
      "6970            1619253.0  \n",
      "6971            2908239.0  \n",
      "6972           13415361.0  \n",
      "6973            1733986.0  \n",
      "6974            2017741.0  \n",
      "\n",
      "[350 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "bball_expenses_2022 = bball_expenses[bball_expenses['Survey Year'] == 2022]\n",
    "bball_expenses_2022.loc[:, 'Institution Name'] = (\n",
    "    bball_expenses_2022['Institution Name']\n",
    "    .str.replace(\"University\", \"\", regex=False)\n",
    "    .str.replace(\"State\", \"St\", regex=False)\n",
    ")\n",
    "bball_expenses_2022.loc[:, 'Institution Name'] = bball_expenses_2022['Institution Name'].str.replace(\"of\", \"\", regex=False).str.replace(\" \", \"\")\n",
    "bball_expenses_2022.loc[:, 'Institution Name'] = bball_expenses_2022['Institution Name'].str.replace(\"of\", \"\", regex=False).str.replace(\" \", \"\")\n",
    "print(bball_expenses_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'win_percent_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Step 1: Merge `bball_expenses` with `result_df` on \"Institution Name\"\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m win_percent_df\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeam\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m win_percent_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeam\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m      3\u001b[0m win_percent_df\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeam\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m win_percent_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeam\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m bball_expenses_2022\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInstitution Name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m bball_expenses_2022[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInstitution Name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'win_percent_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Step 1: Merge `bball_expenses` with `result_df` on \"Institution Name\"\n",
    "win_percent_df.loc[:, 'Team'] = win_percent_df['Team'].str.strip()\n",
    "win_percent_df.loc[:, 'Team'] = win_percent_df['Team'].str.replace(r'\\s+', '', regex=True)\n",
    "bball_expenses_2022.loc[:, 'Institution Name'] = bball_expenses_2022['Institution Name'].str.strip()\n",
    "merged_df = pd.merge(win_percent_df, bball_expenses_2022, left_on=\"Team\", right_on=\"Institution Name\", how=\"outer\")\n",
    "\n",
    "merged_df = merged_df.dropna(subset=['Team'])\n",
    "merged_df = merged_df.dropna(subset=['Institution Name'])\n",
    "\n",
    "\n",
    "\n",
    "print(merged_df)\n",
    "merged_df.to_csv(\"merged_df\", sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not convert ['KansasGonzagaDukeKentuckyMichiganStDaytonMurrayStMemphisXavierFloridaCreightonMarquetteVermontConnecticutSyracuseUtahStVillanovaSanDiegoStBelmontRichmondButlerBoiseStWeberStWinthropLouisvilleNotreDameWichitaStUtahValleyFloridaStTempleTulsaIowaMiamiSaintLouisArkansasOldDominionValparaisoTarletonStOralRobertsIonaPrincetonRiderSanFranciscoMississippiLipscombYaleHarvardVanderbiltArkansasStKansasStSetonHallBucknellDrexelGeorgiaStSeattleWyomingClemsonAuburnOaklandNiagaraRadfordMarshallSantaClaraIowaStMontanaStHoustonMoreheadStBaylorIllinoisStSouthDakotaColgateToledoPortlandStWakeForestStonyBrookRhodeIslandGeorgetownTexasTechHighPointBradleyBallStBellarmineLehighFairfieldDelawareSanDiegoDrakeTroyNorfolkStQuinnipiacHamptonIndianaStTexasStGeorgiaNorthTexasClevelandStLibertyNewOrleansJacksonvilleAmericanLaSalleBrownNorthDakotaMcNeeseStNorthwesternMonmouthCornellDenverUtahTechLamarPepperdineRiceCampbellIdahoElonLindenwoodAlabamaStJacksonStStetsonMorganStEvansvilleTowsonIdahoStPortlandDuquesneBinghamtonMaineBryantDePaulFordhamLongwoodAlcornStCoppinStHowardGramblingStDelawareStKennesawStSanJoseStChicagoSt'] to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m         df[col] \u001b[38;5;241m=\u001b[39m df[col]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Fill NaN values with the mean of each column\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mfillna(df\u001b[38;5;241m.\u001b[39mmean())\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Check if the DataFrame is empty\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39mempty:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:11335\u001b[0m, in \u001b[0;36mDataFrame.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11327\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m  11328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  11329\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11333\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11334\u001b[0m ):\n\u001b[0;32m> 11335\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mmean(axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m  11336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Series):\n\u001b[1;32m  11337\u001b[0m         result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:11992\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11985\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  11986\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  11987\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11990\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11991\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 11992\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[1;32m  11993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m  11994\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:11949\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11945\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[1;32m  11947\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m> 11949\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[1;32m  11950\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[1;32m  11951\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:11204\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m  11200\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m  11202\u001b[0m \u001b[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[1;32m  11203\u001b[0m \u001b[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[0;32m> 11204\u001b[0m res \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mreduce(blk_func)\n\u001b[1;32m  11205\u001b[0m out \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(res, axes\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m  11206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m out\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboolean\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:1459\u001b[0m, in \u001b[0;36mBlockManager.reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m   1457\u001b[0m res_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1458\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m-> 1459\u001b[0m     nbs \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mreduce(func)\n\u001b[1;32m   1460\u001b[0m     res_blocks\u001b[38;5;241m.\u001b[39mextend(nbs)\n\u001b[1;32m   1462\u001b[0m index \u001b[38;5;241m=\u001b[39m Index([\u001b[38;5;28;01mNone\u001b[39;00m])  \u001b[38;5;66;03m# placeholder\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/internals/blocks.py:377\u001b[0m, in \u001b[0;36mBlock.reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m--> 377\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    380\u001b[0m         res_values \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:11136\u001b[0m, in \u001b[0;36mDataFrame._reduce.<locals>.blk_func\u001b[0;34m(values, axis)\u001b[0m\n\u001b[1;32m  11134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([result])\n\u001b[1;32m  11135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m> 11136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    145\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[1;32m    407\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/nanops.py:720\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    718\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[1;32m    719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum)\n\u001b[0;32m--> 720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(the_sum)\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    723\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/nanops.py:1678\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1675\u001b[0m inferred \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(x)\n\u001b[1;32m   1676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1677\u001b[0m     \u001b[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;00m\n\u001b[0;32m-> 1678\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1679\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1680\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mcomplex128)\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not convert ['KansasGonzagaDukeKentuckyMichiganStDaytonMurrayStMemphisXavierFloridaCreightonMarquetteVermontConnecticutSyracuseUtahStVillanovaSanDiegoStBelmontRichmondButlerBoiseStWeberStWinthropLouisvilleNotreDameWichitaStUtahValleyFloridaStTempleTulsaIowaMiamiSaintLouisArkansasOldDominionValparaisoTarletonStOralRobertsIonaPrincetonRiderSanFranciscoMississippiLipscombYaleHarvardVanderbiltArkansasStKansasStSetonHallBucknellDrexelGeorgiaStSeattleWyomingClemsonAuburnOaklandNiagaraRadfordMarshallSantaClaraIowaStMontanaStHoustonMoreheadStBaylorIllinoisStSouthDakotaColgateToledoPortlandStWakeForestStonyBrookRhodeIslandGeorgetownTexasTechHighPointBradleyBallStBellarmineLehighFairfieldDelawareSanDiegoDrakeTroyNorfolkStQuinnipiacHamptonIndianaStTexasStGeorgiaNorthTexasClevelandStLibertyNewOrleansJacksonvilleAmericanLaSalleBrownNorthDakotaMcNeeseStNorthwesternMonmouthCornellDenverUtahTechLamarPepperdineRiceCampbellIdahoElonLindenwoodAlabamaStJacksonStStetsonMorganStEvansvilleTowsonIdahoStPortlandDuquesneBinghamtonMaineBryantDePaulFordhamLongwoodAlcornStCoppinStHowardGramblingStDelawareStKennesawStSanJoseStChicagoSt'] to numeric"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df = merged_df\n",
    "\n",
    "# Convert percentage strings to floats\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object' and df[col].str.contains('%').any():\n",
    "        df[col] = df[col].str.replace('%', '').astype(float)\n",
    "\n",
    "# Fill NaN values with the mean of each column\n",
    "df = df.fillna(df.mean())\n",
    "\n",
    "# Check if the DataFrame is empty\n",
    "if df.empty:\n",
    "    print(\"The DataFrame is empty after handling NaNs. Please check the data source.\")\n",
    "else:\n",
    "    # Definding target variables/predictor and indicator variables\n",
    "    Y = df['home_winLoss_Win_percent']\n",
    "    X = df.drop(columns=['home_winLoss_Win_percent', 'Team', 'Institution Name_x', 'Institution Name_y', \n",
    "                         'Best_Match_in_Team', 'Survey Year', 'UNITID', 'OPE ID', 'State CD'])\n",
    "\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "\n",
    "    model = sm.OLS(Y, X).fit()\n",
    "\n",
    "    print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
