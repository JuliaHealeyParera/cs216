{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "downloaded datasets from https://www.sports-reference.com/cbb/schools/connecticut/men/2025.html#all_roster with two csv's per team, one of roster for year (upperclassmen) and one of per game for starters, with team totals in same table having info on the field goals, free throws, etc aka common bbal stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: 2024-25 uconn.html\n",
      "Processing table with div ID: all_roster in team 2024-25 uconn\n",
      "Headers: ['Player', '#', 'Class', 'Pos', 'Height', 'Weight', 'Hometown', 'High School', 'RSCI Top 100', 'Summary']\n",
      "Table 'all_roster' for team '2024-25 uconn' saved to ../2024-25 uconn_all_roster.csv\n",
      "Processing table with div ID: all_advanced_players in team 2024-25 uconn\n",
      "Headers: ['Rk', 'Player', 'G', 'GS', 'MP', 'PER', 'TS%', 'eFG%', '3PAr', 'FTr', 'PProd', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', '', 'OWS', 'DWS', 'WS', 'WS/40', '', 'OBPM', 'DBPM', 'BPM']\n",
      "Table 'all_advanced_players' for team '2024-25 uconn' saved to ../2024-25 uconn_all_advanced_players.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing the HTML files\n",
    "html_folder = '../data/html_sportsreference'\n",
    "output_folder = '../'  # Directory to save CSV files\n",
    "\n",
    "# List of table div IDs to extract\n",
    "table_div_ids = ['all_roster', 'all_advanced_players']\n",
    "\n",
    "# Loop through each HTML file in the folder\n",
    "for filename in os.listdir(html_folder):\n",
    "    if filename.endswith(\".html\"):\n",
    "        print(f\"Processing file: {filename}\")\n",
    "        file_path = os.path.join(html_folder, filename)\n",
    "\n",
    "        # Open and parse the HTML file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            soup = BeautifulSoup(file, 'html.parser')\n",
    "\n",
    "        # Extract team name from filename (without .html)\n",
    "        team_name = os.path.splitext(filename)[0]\n",
    "\n",
    "        # Loop through each table ID\n",
    "        for div_id in table_div_ids:\n",
    "            print(f\"Processing table with div ID: {div_id} in team {team_name}\")\n",
    "            div = soup.find('div', id=div_id)\n",
    "            if div:\n",
    "                table = div.find('table')  # Locate the table inside the div\n",
    "                if table:\n",
    "                    # Extract headers from <thead>\n",
    "                    thead = table.find('thead')\n",
    "                    headers = [header.text.strip() for header in thead.find_all('th')] if thead else []\n",
    "                    print(\"Headers:\", headers)\n",
    "\n",
    "                    # Extract rows from <tbody>\n",
    "                    tbody = table.find('tbody')\n",
    "                    rows = []\n",
    "                    if tbody:\n",
    "                        for row in tbody.find_all('tr'):\n",
    "                            cells = row.find_all('td')\n",
    "                            row_data = [cell.text.strip() for cell in cells]\n",
    "                            # Check if the row length matches headers\n",
    "                            if len(row_data) == len(headers):\n",
    "                                rows.append(row_data)\n",
    "                            else:\n",
    "                                #print(f\"Row length mismatch in table '{div_id}':\", row_data)\n",
    "                                # Pad the row to match headers\n",
    "                                row_data.extend([''] * (len(headers) - len(row_data)))\n",
    "                                rows.append(row_data)\n",
    "\n",
    "                    # Convert to DataFrame\n",
    "                    if rows:\n",
    "                        df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "                        # Save to CSV with team name and table ID\n",
    "                        csv_filename = f\"{team_name}_{div_id}.csv\"\n",
    "                        csv_path = os.path.join(output_folder, csv_filename)\n",
    "                        df.to_csv(csv_path, index=False)\n",
    "                        print(f\"Table '{div_id}' for team '{team_name}' saved to {csv_path}\")\n",
    "                    else:\n",
    "                        print(f\"No valid rows found for table '{div_id}' in team '{team_name}'\")\n",
    "                else:\n",
    "                    print(f\"No table found with ID '{div_id}' for team '{team_name}'\")\n",
    "            else:\n",
    "                print(f\"No div found with ID '{div_id}' for team '{team_name}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
