{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "web scraper using beautiful soup to get the table from teamrankings.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Directory where your HTML files are stored\n",
    "directory_path = '../data/html_teamranking/'\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith(\".html\"):\n",
    "        # Construct full file path\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        # Open and parse each HTML file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            soup = BeautifulSoup(file, 'html.parser')\n",
    "        \n",
    "        # Locate the table\n",
    "        table = soup.find('table')\n",
    "        if not table:\n",
    "            print(f\"No table found in {filename}\")\n",
    "            continue  # Skip to next file if no table found\n",
    "\n",
    "        # Extract headers\n",
    "        headers = [header.text.strip() for header in table.find_all('th')]\n",
    "\n",
    "        # Extract rows\n",
    "        rows = []\n",
    "        for row in table.find_all('tr'):\n",
    "            cells = row.find_all('td')\n",
    "            row_data = [cell.text.strip() for cell in cells]\n",
    "            if row_data:\n",
    "                rows.append(row_data)\n",
    "        \n",
    "        # Save data to a new CSV file\n",
    "        csv_filename = filename.replace('.html', '.csv')\n",
    "        csv_path = os.path.join(directory_path, csv_filename)\n",
    "        \n",
    "        with open(csv_path, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(headers)  # Write headers\n",
    "            writer.writerows(rows)    # Write data rows\n",
    "        print(f\"Data from {filename} has been saved to {csv_filename}\")\n",
    "\n",
    "print(\"All files processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#initializing so there's no yellow lines lol\n",
    "afterLoss_winLoss = 0\n",
    "afterWin_winLoss = 0\n",
    "asUnderdog_winLoss = 0\n",
    "restAdvantage_winLoss = 0\n",
    "equalRest_winLoss = 0\n",
    "away_winLoss = 0\n",
    "home_winLoss = 0\n",
    "neutralSite_winLoss = 0\n",
    "overallWinPercentage=0\n",
    "\n",
    "# Directory where your CSV files are stored\n",
    "directory_path = '../data/html_teamranking/'\n",
    "\n",
    "# Loop through each CSV file in the directory and create DataFrames\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        # Construct full file path\n",
    "        csv_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        # Read CSV into a DataFrame\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Use filename as the name of the DataFrame (without \".csv\")\n",
    "        exec(f\"{filename.replace('.csv', '')} = df\")\n",
    "        \n",
    "        # Print to confirm\n",
    "        print(f\"DataFrame created for {filename}\")\n",
    "\n",
    "team_expenses = pd.read_csv(\"../data/Sport_Data_2003_2004_2005_2006_2007_2008_2009_2010_2011_2012_2013_2014_2015_2016_2017_2018_2019_2020_2021_2022.csv\")\n",
    "print(f\"DataFrame created for Sport_Data_2003_2004_2005_2006_2007_2008_2009_2010_2011_2012_2013_2014_2015_2016_2017_2018_2019_2020_2021_2022\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------these datasets range from the 2003-2004 season to 2024-2025 season (current)\n",
    "\n",
    "#previous game was a loss -> is the next game a win/loss?\n",
    "afterLoss_winLoss\n",
    "\n",
    "#previous game was a win -> is the next game a win/loss?\n",
    "afterWin_winLoss\n",
    "\n",
    "#games won/lost as the underdog aka lower team ranking/seeding\n",
    "asUnderdog_winLoss\n",
    "\n",
    "#games won/lost WITH a rest advantage, or having 1+ days of rest compared to the other team\n",
    "restAdvantage_winLoss\n",
    "\n",
    "#games won/lost with equal days rest compared to the other team (baseline for restAdvantange)\n",
    "equalRest_winLoss\n",
    "\n",
    "#games won/lost as the away team\n",
    "away_winLoss\n",
    "\n",
    "#games won/lost as the home team\n",
    "home_winLoss\n",
    "\n",
    "#games won/lost playing on a neutral site (might be useful to compare as baseline agasint home/away)\n",
    "neutralSite_winLoss\n",
    "\n",
    "#total wins and losses of every game\n",
    "overallWinPercentage\n",
    "\n",
    "#total team expenses \n",
    "bball_expenses = team_expenses[[\"Survey Year\", \"UNITID\", \"OPE ID\", \"Institution Name\", \"State CD\", \"Expenses Men's Team\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
