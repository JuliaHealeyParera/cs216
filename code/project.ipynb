{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "web scraper using beautiful soup to get the table from teamrankings.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from away_winLoss.html has been saved to away_winLoss.csv\n",
      "No table found in all_bbalcolleges.html\n",
      "Data from overallWinPercentage.html has been saved to overallWinPercentage.csv\n",
      "Data from asUnderdog_winLoss.html has been saved to asUnderdog_winLoss.csv\n",
      "Data from equalRest_winLoss.html has been saved to equalRest_winLoss.csv\n",
      "Data from afterLoss_winLoss.html has been saved to afterLoss_winLoss.csv\n",
      "Data from restAdvantage_winLoss.html has been saved to restAdvantage_winLoss.csv\n",
      "Data from home_winLoss.html has been saved to home_winLoss.csv\n",
      "Data from neutralSite_winLoss.html has been saved to neutralSite_winLoss.csv\n",
      "Data from afterWin_winLoss.html has been saved to afterWin_winLoss.csv\n",
      "All files processed.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Directory where your HTML files are stored\n",
    "directory_path = '../data/html_teamranking/'\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith(\".html\"):\n",
    "        # Construct full file path\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        # Open and parse each HTML file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            soup = BeautifulSoup(file, 'html.parser')\n",
    "        \n",
    "        # Locate the table\n",
    "        table = soup.find('table')\n",
    "        if not table:\n",
    "            print(f\"No table found in {filename}\")\n",
    "            continue  # Skip to next file if no table found\n",
    "\n",
    "        # Extract headers\n",
    "        headers = [header.text.strip() for header in table.find_all('th')]\n",
    "\n",
    "        # Extract rows\n",
    "        rows = []\n",
    "        for row in table.find_all('tr'):\n",
    "            cells = row.find_all('td')\n",
    "            row_data = [cell.text.strip() for cell in cells]\n",
    "            if row_data:\n",
    "                rows.append(row_data)\n",
    "        \n",
    "        # Save data to a new CSV file\n",
    "        csv_filename = filename.replace('.html', '.csv')\n",
    "        csv_path = os.path.join(directory_path, csv_filename)\n",
    "        \n",
    "        with open(csv_path, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(headers)  # Write headers\n",
    "            writer.writerows(rows)    # Write data rows\n",
    "        print(f\"Data from {filename} has been saved to {csv_filename}\")\n",
    "\n",
    "print(\"All files processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame created for afterLoss_winLoss.csv\n",
      "DataFrame created for asUnderdog_winLoss.csv\n",
      "DataFrame created for restAdvantage_winLoss.csv\n",
      "DataFrame created for overallWinPercentage.csv\n",
      "DataFrame created for neutralSite_winLoss.csv\n",
      "DataFrame created for equalRest_winLoss.csv\n",
      "DataFrame created for away_winLoss.csv\n",
      "DataFrame created for afterWin_winLoss.csv\n",
      "DataFrame created for home_winLoss.csv\n",
      "DataFrame created for Sport_Data_2003_2004_2005_2006_2007_2008_2009_2010_2011_2012_2013_2014_2015_2016_2017_2018_2019_2020_2021_2022\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#initializing so there's no yellow lines lol\n",
    "afterLoss_winLoss = 0\n",
    "afterWin_winLoss = 0\n",
    "asUnderdog_winLoss = 0\n",
    "restAdvantage_winLoss = 0\n",
    "equalRest_winLoss = 0\n",
    "away_winLoss = 0\n",
    "home_winLoss = 0\n",
    "neutralSite_winLoss = 0\n",
    "overallWinPercentage=0\n",
    "\n",
    "# Directory where your CSV files are stored\n",
    "directory_path = '../data/html_teamranking/'\n",
    "\n",
    "# Loop through each CSV file in the directory and create DataFrames\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        # Construct full file path\n",
    "        csv_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        # Read CSV into a DataFrame\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Use filename as the name of the DataFrame (without \".csv\")\n",
    "        exec(f\"{filename.replace('.csv', '')} = df\")\n",
    "        \n",
    "        # Print to confirm\n",
    "        print(f\"DataFrame created for {filename}\")\n",
    "\n",
    "team_expenses = pd.read_csv(\"../data/Sport_Data_2003_2004_2005_2006_2007_2008_2009_2010_2011_2012_2013_2014_2015_2016_2017_2018_2019_2020_2021_2022.csv\")\n",
    "print(f\"DataFrame created for Sport_Data_2003_2004_2005_2006_2007_2008_2009_2010_2011_2012_2013_2014_2015_2016_2017_2018_2019_2020_2021_2022\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------these datasets range from the 2003-2004 season to 2024-2025 season (current)\n",
    "\n",
    "#previous game was a loss -> is the next game a win/loss?\n",
    "afterLoss_winLoss\n",
    "\n",
    "#previous game was a win -> is the next game a win/loss?\n",
    "afterWin_winLoss\n",
    "\n",
    "#games won/lost as the underdog aka lower team ranking/seeding\n",
    "asUnderdog_winLoss\n",
    "\n",
    "#games won/lost WITH a rest advantage, or having 1+ days of rest compared to the other team\n",
    "restAdvantage_winLoss\n",
    "\n",
    "#games won/lost with equal days rest compared to the other team (baseline for restAdvantange)\n",
    "equalRest_winLoss\n",
    "\n",
    "#games won/lost as the away team\n",
    "away_winLoss\n",
    "\n",
    "#games won/lost as the home team\n",
    "home_winLoss\n",
    "\n",
    "#games won/lost playing on a neutral site (might be useful to compare as baseline agasint home/away)\n",
    "neutralSite_winLoss\n",
    "\n",
    "#total wins and losses of every game\n",
    "overallWinPercentage\n",
    "\n",
    "#total team expenses \n",
    "bball_expenses = team_expenses[[\"Survey Year\", \"UNITID\", \"OPE ID\", \"Institution Name\", \"State CD\", \"Expenses Men's Team\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fuzzywuzzy[speedup] in /Users/angiehuang/mambaforge/lib/python3.10/site-packages (0.18.0)\n",
      "Requirement already satisfied: python-levenshtein>=0.12 in /Users/angiehuang/mambaforge/lib/python3.10/site-packages (from fuzzywuzzy[speedup]) (0.26.1)\n",
      "Requirement already satisfied: Levenshtein==0.26.1 in /Users/angiehuang/mambaforge/lib/python3.10/site-packages (from python-levenshtein>=0.12->fuzzywuzzy[speedup]) (0.26.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /Users/angiehuang/mambaforge/lib/python3.10/site-packages (from Levenshtein==0.26.1->python-levenshtein>=0.12->fuzzywuzzy[speedup]) (3.10.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install fuzzywuzzy[speedup]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "def custom_score(str1, str2):\n",
    "    \"\"\"\n",
    "    Custom scoring function that penalizes missing words less.\n",
    "    Uses fuzz.partial_ratio for lenient matching, with extra weight for fewer missing words.\n",
    "    \"\"\"\n",
    "    # First get the basic partial match score\n",
    "    partial_score = fuzz.partial_ratio(str1, str2)\n",
    "    \n",
    "    # Adjust the score based on the length of the two strings (i.e., fewer words missing is better)\n",
    "    word_diff_penalty = abs(len(str1.split()) - len(str2.split()))\n",
    "    \n",
    "    # Optionally, add a small penalty for missing words\n",
    "    adjusted_score = partial_score - (word_diff_penalty * 2)  # Adjust the factor for leniency\n",
    "    \n",
    "    # Ensure the score stays within 0-100\n",
    "    return max(min(adjusted_score, 100), 0)\n",
    "\n",
    "def find_best_match_between_dfs(df1, column1, df2, column2, threshold=80):\n",
    "    \"\"\"\n",
    "    Finds the best fuzzy match for each item in `column1` from `df1` within the entire `column2` from `df2`.\n",
    "    Returns a new DataFrame with original names, best matches, and scores using custom scoring for partial matching.\n",
    "    \"\"\"\n",
    "    matches = []\n",
    "    \n",
    "    for item in df1[column1]:\n",
    "        # Extract the best match and custom score\n",
    "        match_data = process.extractOne(item, df2[column2], scorer=lambda str1, str2: custom_score(str1, str2))\n",
    "        if match_data:\n",
    "            best_match = match_data[0]  # Best match string\n",
    "            score = match_data[1]       # Similarity score\n",
    "        else:\n",
    "            best_match = None\n",
    "            score = None\n",
    "        \n",
    "        # Append results if they meet the threshold\n",
    "        matches.append({\n",
    "            column1: item,\n",
    "            f'Best_Match_in_{column2}': best_match if score and score >= threshold else None,\n",
    "            f'Match_Score_in_{column2}': score if score and score >= threshold else None\n",
    "        })\n",
    "    \n",
    "    # Create and return a new DataFrame with matches and scores\n",
    "    return pd.DataFrame(matches)\n",
    "\n",
    "result_df = find_best_match_between_dfs(bball_expenses, 'Institution Name', afterLoss_winLoss, 'Team')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Institution Name Best_Match_in_Team  \\\n",
      "0            Abilene Christian University      Hsn Christian   \n",
      "1                Alabama A & M University            Alabama   \n",
      "2                Alabama State University         Alabama St   \n",
      "3                 Alcorn State University          Alcorn St   \n",
      "4                     American University           American   \n",
      "...                                   ...                ...   \n",
      "6970                  Winthrop University           Winthrop   \n",
      "6971  Wright State University-Main Campus          Wright St   \n",
      "6972                    Xavier University             Xavier   \n",
      "6973                      Yale University               Yale   \n",
      "6974          Youngstown State University           NC State   \n",
      "\n",
      "      Match_Score_in_Team  \n",
      "0                    83.0  \n",
      "1                    94.0  \n",
      "2                    98.0  \n",
      "3                    98.0  \n",
      "4                    98.0  \n",
      "...                   ...  \n",
      "6970                 98.0  \n",
      "6971                 94.0  \n",
      "6972                 98.0  \n",
      "6973                 98.0  \n",
      "6974                 86.0  \n",
      "\n",
      "[6975 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(result_df)\n",
    "team_names = result_df\n",
    "\n",
    "#this team_names dataset is relating the \"Institution Name\" from the ball_expenses dataframe to the \n",
    "# teamranking ones ie afterLoss_winLoss \"Team\" names\n",
    "\n",
    "#---------------THIS TEAM_NAMES IS ALSO NOT PERFECT SO THERE ARE WRONG RELATIONS AND THINGS BC I AUTOMATED, PLEASE HELP CHECK AND EDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
