{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "web scraper using beautiful soup to get the table from teamrankings.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from afterLoss_winLoss.html has been saved to afterLoss_winLoss.csv\n",
      "Data from afterWin_winLoss.html has been saved to afterWin_winLoss.csv\n",
      "No table found in all_bbalcolleges.html\n",
      "Data from asUnderdog_winLoss.html has been saved to asUnderdog_winLoss.csv\n",
      "Data from away_winLoss.html has been saved to away_winLoss.csv\n",
      "Data from equalRest_winLoss.html has been saved to equalRest_winLoss.csv\n",
      "Data from home_winLoss.html has been saved to home_winLoss.csv\n",
      "Data from neutralSite_winLoss.html has been saved to neutralSite_winLoss.csv\n",
      "Data from overallWinPercentage.html has been saved to overallWinPercentage.csv\n",
      "Data from restAdvantage_winLoss.html has been saved to restAdvantage_winLoss.csv\n",
      "All files processed.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Directory where your HTML files are stored\n",
    "directory_path = '../data/html_teamranking/'\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith(\".html\"):\n",
    "        # Construct full file path\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        # Open and parse each HTML file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            soup = BeautifulSoup(file, 'html.parser')\n",
    "        \n",
    "        # Locate the table\n",
    "        table = soup.find('table')\n",
    "        if not table:\n",
    "            print(f\"No table found in {filename}\")\n",
    "            continue  # Skip to next file if no table found\n",
    "\n",
    "        # Extract headers\n",
    "        headers = [header.text.strip() for header in table.find_all('th')]\n",
    "\n",
    "        # Extract rows\n",
    "        rows = []\n",
    "        for row in table.find_all('tr'):\n",
    "            cells = row.find_all('td')\n",
    "            row_data = [cell.text.strip() for cell in cells]\n",
    "            if row_data:\n",
    "                rows.append(row_data)\n",
    "        \n",
    "        # Save data to a new CSV file\n",
    "        csv_filename = filename.replace('.html', '.csv')\n",
    "        csv_path = os.path.join(directory_path, csv_filename)\n",
    "        \n",
    "        with open(csv_path, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(headers)  # Write headers\n",
    "            writer.writerows(rows)    # Write data rows\n",
    "        print(f\"Data from {filename} has been saved to {csv_filename}\")\n",
    "\n",
    "print(\"All files processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame created for afterLoss_winLoss.csv\n",
      "DataFrame created for afterWin_winLoss.csv\n",
      "DataFrame created for asUnderdog_winLoss.csv\n",
      "DataFrame created for away_winLoss.csv\n",
      "DataFrame created for equalRest_winLoss.csv\n",
      "DataFrame created for home_winLoss.csv\n",
      "DataFrame created for neutralSite_winLoss.csv\n",
      "DataFrame created for overallWinPercentage.csv\n",
      "DataFrame created for restAdvantage_winLoss.csv\n",
      "DataFrame created for Sport_Data_2003_2004_2005_2006_2007_2008_2009_2010_2011_2012_2013_2014_2015_2016_2017_2018_2019_2020_2021_2022\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#initializing so there's no yellow lines lol\n",
    "afterLoss_winLoss = 0\n",
    "afterWin_winLoss = 0\n",
    "asUnderdog_winLoss = 0\n",
    "restAdvantage_winLoss = 0\n",
    "equalRest_winLoss = 0\n",
    "away_winLoss = 0\n",
    "home_winLoss = 0\n",
    "neutralSite_winLoss = 0\n",
    "overallWinPercentage=0\n",
    "\n",
    "# Directory where your CSV files are stored\n",
    "directory_path = '../data/html_teamranking/'\n",
    "\n",
    "# Loop through each CSV file in the directory and create DataFrames\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        # Construct full file path\n",
    "        csv_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        # Read CSV into a DataFrame\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Use filename as the name of the DataFrame (without \".csv\")\n",
    "        exec(f\"{filename.replace('.csv', '')} = df\")\n",
    "        \n",
    "        # Print to confirm\n",
    "        print(f\"DataFrame created for {filename}\")\n",
    "\n",
    "team_expenses = pd.read_csv(\"../data/Sport_Data_2003_2004_2005_2006_2007_2008_2009_2010_2011_2012_2013_2014_2015_2016_2017_2018_2019_2020_2021_2022.csv\")\n",
    "print(f\"DataFrame created for Sport_Data_2003_2004_2005_2006_2007_2008_2009_2010_2011_2012_2013_2014_2015_2016_2017_2018_2019_2020_2021_2022\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------these datasets range from the 2003-2004 season to 2024-2025 season (current)\n",
    "\n",
    "#previous game was a loss -> is the next game a win/loss?\n",
    "afterLoss_winLoss\n",
    "\n",
    "#previous game was a win -> is the next game a win/loss?\n",
    "afterWin_winLoss\n",
    "\n",
    "#games won/lost as the underdog aka lower team ranking/seeding\n",
    "asUnderdog_winLoss\n",
    "\n",
    "#games won/lost WITH a rest advantage, or having 1+ days of rest compared to the other team\n",
    "restAdvantage_winLoss\n",
    "\n",
    "#games won/lost with equal days rest compared to the other team (baseline for restAdvantange)\n",
    "equalRest_winLoss\n",
    "\n",
    "#games won/lost as the away team\n",
    "away_winLoss\n",
    "\n",
    "#games won/lost as the home team\n",
    "home_winLoss\n",
    "\n",
    "#games won/lost playing on a neutral site (might be useful to compare as baseline agasint home/away)\n",
    "neutralSite_winLoss\n",
    "\n",
    "#total wins and losses of every game\n",
    "overallWinPercentage\n",
    "\n",
    "#total team expenses \n",
    "bball_expenses = team_expenses[[\"Survey Year\", \"UNITID\", \"OPE ID\", \"Institution Name\", \"State CD\", \"Expenses Men's Team\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fuzzywuzzy[speedup]\n",
      "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting python-levenshtein>=0.12 (from fuzzywuzzy[speedup])\n",
      "  Downloading python_Levenshtein-0.26.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting Levenshtein==0.26.1 (from python-levenshtein>=0.12->fuzzywuzzy[speedup])\n",
      "  Downloading levenshtein-0.26.1-cp310-cp310-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.26.1->python-levenshtein>=0.12->fuzzywuzzy[speedup])\n",
      "  Downloading rapidfuzz-3.10.1-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Downloading python_Levenshtein-0.26.1-py3-none-any.whl (9.4 kB)\n",
      "Downloading levenshtein-0.26.1-cp310-cp310-win_amd64.whl (98 kB)\n",
      "   ---------------------------------------- 98.1/98.1 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Downloading rapidfuzz-3.10.1-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 1.6/1.6 MB 12.8 MB/s eta 0:00:00\n",
      "Installing collected packages: fuzzywuzzy, rapidfuzz, Levenshtein, python-levenshtein\n",
      "Successfully installed Levenshtein-0.26.1 fuzzywuzzy-0.18.0 python-levenshtein-0.26.1 rapidfuzz-3.10.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\14253\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install \"fuzzywuzzy[speedup]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "def custom_score(str1, str2):\n",
    "    \"\"\"\n",
    "    Custom scoring function that penalizes missing words less.\n",
    "    Uses fuzz.partial_ratio for lenient matching, with extra weight for fewer missing words.\n",
    "    \"\"\"\n",
    "    # First get the basic partial match score\n",
    "    partial_score = fuzz.partial_ratio(str1, str2)\n",
    "    \n",
    "    # Adjust the score based on the length of the two strings (i.e., fewer words missing is better)\n",
    "    word_diff_penalty = abs(len(str1.split()) - len(str2.split()))\n",
    "    \n",
    "    # Optionally, add a small penalty for missing words\n",
    "    adjusted_score = partial_score - (word_diff_penalty * 2)  # Adjust the factor for leniency\n",
    "    \n",
    "    # Ensure the score stays within 0-100\n",
    "    return max(min(adjusted_score, 100), 0)\n",
    "\n",
    "def find_best_match_between_dfs(df1, column1, df2, column2, threshold=80):\n",
    "    \"\"\"\n",
    "    Finds the best fuzzy match for each item in `column1` from `df1` within the entire `column2` from `df2`.\n",
    "    Returns a new DataFrame with original names, best matches, and scores using custom scoring for partial matching.\n",
    "    \"\"\"\n",
    "    matches = []\n",
    "    \n",
    "    for item in df1[column1]:\n",
    "        # Extract the best match and custom score\n",
    "        match_data = process.extractOne(item, df2[column2], scorer=lambda str1, str2: custom_score(str1, str2))\n",
    "        if match_data:\n",
    "            best_match = match_data[0]  # Best match string\n",
    "            score = match_data[1]       # Similarity score\n",
    "        else:\n",
    "            best_match = None\n",
    "            score = None\n",
    "        \n",
    "        # Append results if they meet the threshold\n",
    "        matches.append({\n",
    "            column1: item,\n",
    "            f'Best_Match_in_{column2}': best_match if score and score >= threshold else None,\n",
    "            f'Match_Score_in_{column2}': score if score and score >= threshold else None\n",
    "        })\n",
    "    \n",
    "    # Create and return a new DataFrame with matches and scores\n",
    "    return pd.DataFrame(matches)\n",
    "\n",
    "result_df = find_best_match_between_dfs(bball_expenses, 'Institution Name', afterLoss_winLoss, 'Team')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Institution Name Best_Match_in_Team  \\\n",
      "0            Abilene Christian University      Hsn Christian   \n",
      "1                Alabama A & M University            Alabama   \n",
      "2                Alabama State University         Alabama St   \n",
      "3                 Alcorn State University          Alcorn St   \n",
      "4                     American University           American   \n",
      "...                                   ...                ...   \n",
      "6970                  Winthrop University           Winthrop   \n",
      "6971  Wright State University-Main Campus          Wright St   \n",
      "6972                    Xavier University             Xavier   \n",
      "6973                      Yale University               Yale   \n",
      "6974          Youngstown State University           NC State   \n",
      "\n",
      "      Match_Score_in_Team  \n",
      "0                    83.0  \n",
      "1                    94.0  \n",
      "2                    98.0  \n",
      "3                    98.0  \n",
      "4                    98.0  \n",
      "...                   ...  \n",
      "6970                 98.0  \n",
      "6971                 94.0  \n",
      "6972                 98.0  \n",
      "6973                 98.0  \n",
      "6974                 86.0  \n",
      "\n",
      "[6975 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(result_df)\n",
    "team_names = result_df\n",
    "\n",
    "#this team_names dataset is relating the \"Institution Name\" from the ball_expenses dataframe to the \n",
    "# teamranking ones ie afterLoss_winLoss \"Team\" names\n",
    "\n",
    "#---------------THIS TEAM_NAMES IS ALSO NOT PERFECT SO THERE ARE WRONG RELATIONS AND THINGS BC I AUTOMATED, PLEASE HELP CHECK AND EDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {\n",
    "    \"afterLoss_winLoss\": afterLoss_winLoss,\n",
    "    \"afterWin_winLoss\": afterWin_winLoss,\n",
    "    \"asUnderdog_winLoss\": asUnderdog_winLoss,\n",
    "    \"restAdvantage_winLoss\": restAdvantage_winLoss,\n",
    "    \"equalRest_winLoss\": equalRest_winLoss,\n",
    "    \"away_winLoss\": away_winLoss,\n",
    "    \"home_winLoss\": home_winLoss,\n",
    "    \"neutralSite_winLoss\": neutralSite_winLoss,\n",
    "    \"overallWinPercentage\": overallWinPercentage\n",
    "}\n",
    "\n",
    "# Rename the win percentage column for each DataFrame\n",
    "for name, df in dfs.items():\n",
    "    # Replace 'Win %' with the formatted name, e.g., 'afterLoss_winLoss_win_percent'\n",
    "    df.rename(columns={\"Win %\": f\"{name}_Win_percent\"}, inplace=True)\n",
    "    df.rename(columns={\"MOV\": f\"{name}_MOV\"}, inplace=True)\n",
    "    df.rename(columns={\"ATS +/-\": f\"{name}_ATS\"}, inplace=True)\n",
    "    df.drop('Win-Loss Record', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>afterLoss_winLoss_Win_percent</th>\n",
       "      <th>afterLoss_winLoss_MOV</th>\n",
       "      <th>afterLoss_winLoss_ATS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mercyhurst</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>85.2%</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gonzaga</td>\n",
       "      <td>82.1%</td>\n",
       "      <td>14.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Duke</td>\n",
       "      <td>78.9%</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>72.7%</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Team afterLoss_winLoss_Win_percent  afterLoss_winLoss_MOV  \\\n",
       "0  Mercyhurst                        100.0%                    5.0   \n",
       "1      Kansas                         85.2%                   12.5   \n",
       "2     Gonzaga                         82.1%                   14.9   \n",
       "3        Duke                         78.9%                   13.0   \n",
       "4    Kentucky                         72.7%                    9.3   \n",
       "\n",
       "   afterLoss_winLoss_ATS  \n",
       "0                   12.5  \n",
       "1                    2.3  \n",
       "2                    2.0  \n",
       "3                    0.8  \n",
       "4                    0.6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(afterLoss_winLoss.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge win % datasets\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "merged_win_loss_stats = reduce(lambda left, right: pd.merge(left, right, on=\"Team\", how=\"outer\"), dfs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Team afterLoss_winLoss_Win_percent afterWin_winLoss_Win_percent  \\\n",
      "0     Mercyhurst                        100.0%                          NaN   \n",
      "1         Kansas                         85.2%                        79.6%   \n",
      "2        Gonzaga                         82.1%                        82.7%   \n",
      "3           Duke                         78.9%                        81.5%   \n",
      "4       Kentucky                         72.7%                        76.1%   \n",
      "..           ...                           ...                          ...   \n",
      "359  San Jose St                         26.1%                        37.5%   \n",
      "360  Ark Pine Bl                         25.1%                        41.6%   \n",
      "361  Miss Val St                         24.0%                        51.2%   \n",
      "362   Chicago St                         22.3%                        31.5%   \n",
      "363    W Georgia                          0.0%                          NaN   \n",
      "\n",
      "    asUnderdog_winLoss_Win_percent restAdvantage_winLoss_Win_percent  \\\n",
      "0                            50.0%                               NaN   \n",
      "1                            42.7%                             83.7%   \n",
      "2                            40.5%                             86.3%   \n",
      "3                            43.3%                             82.5%   \n",
      "4                            40.0%                             76.4%   \n",
      "..                             ...                               ...   \n",
      "359                          17.5%                             45.0%   \n",
      "360                          12.8%                             28.1%   \n",
      "361                           9.4%                             24.2%   \n",
      "362                          12.3%                             36.5%   \n",
      "363                           0.0%                               NaN   \n",
      "\n",
      "    equalRest_winLoss_Win_percent away_winLoss_Win_percent  \\\n",
      "0                           50.0%                    33.3%   \n",
      "1                           77.1%                    65.6%   \n",
      "2                           83.1%                    76.1%   \n",
      "3                           81.7%                    66.3%   \n",
      "4                           74.7%                    60.6%   \n",
      "..                            ...                      ...   \n",
      "359                         24.4%                    17.4%   \n",
      "360                         32.4%                    18.1%   \n",
      "361                         36.6%                    17.5%   \n",
      "362                         19.1%                    11.3%   \n",
      "363                          0.0%                    20.0%   \n",
      "\n",
      "    home_winLoss_Win_percent neutralSite_winLoss_Win_percent  \\\n",
      "0                        NaN                            0.0%   \n",
      "1                      93.3%                           74.9%   \n",
      "2                      93.2%                           73.4%   \n",
      "3                      91.7%                           80.2%   \n",
      "4                      88.0%                           69.2%   \n",
      "..                       ...                             ...   \n",
      "359                    44.0%                           28.4%   \n",
      "360                    47.9%                           39.6%   \n",
      "361                    56.2%                           31.3%   \n",
      "362                    44.1%                           32.2%   \n",
      "363                      NaN                             NaN   \n",
      "\n",
      "    overallWinPercentage_Win_percent  \n",
      "0                              25.0%  \n",
      "1                              80.7%  \n",
      "2                              82.8%  \n",
      "3                              81.5%  \n",
      "4                              75.5%  \n",
      "..                               ...  \n",
      "359                            30.7%  \n",
      "360                            29.2%  \n",
      "361                            31.7%  \n",
      "362                            24.8%  \n",
      "363                            20.0%  \n",
      "\n",
      "[364 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame that only includes the columns with 'Win_percent' in their name\n",
    "win_percent_columns = [col for col in merged_win_loss_stats.columns if 'Win_percent' in col]\n",
    "\n",
    "win_percent_df = merged_win_loss_stats[['Team'] + win_percent_columns]\n",
    "print(win_percent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Survey Year', 'UNITID', 'OPE ID', 'Institution Name', 'State CD',\n",
      "       'Expenses Men's Team'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "bball_expenses_2022 = bball_expenses[bball_expenses['Survey Year'] == 2022]\n",
    "print(bball_expenses_2022.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Team afterLoss_winLoss_Win_percent afterWin_winLoss_Win_percent  \\\n",
      "0     Mercyhurst                        100.0%                          NaN   \n",
      "1         Kansas                         85.2%                        79.6%   \n",
      "7        Gonzaga                         82.1%                        82.7%   \n",
      "8           Duke                         78.9%                        81.5%   \n",
      "9       Kentucky                         72.7%                        76.1%   \n",
      "..           ...                           ...                          ...   \n",
      "374  Delaware St                         28.5%                        49.8%   \n",
      "375  Kennesaw St                         27.2%                        41.3%   \n",
      "376  San Jose St                         26.1%                        37.5%   \n",
      "377   Chicago St                         22.3%                        31.5%   \n",
      "380          NaN                           NaN                          NaN   \n",
      "\n",
      "    asUnderdog_winLoss_Win_percent restAdvantage_winLoss_Win_percent  \\\n",
      "0                            50.0%                               NaN   \n",
      "1                            42.7%                             83.7%   \n",
      "7                            40.5%                             86.3%   \n",
      "8                            43.3%                             82.5%   \n",
      "9                            40.0%                             76.4%   \n",
      "..                             ...                               ...   \n",
      "374                          13.2%                             35.5%   \n",
      "375                          13.3%                             47.0%   \n",
      "376                          17.5%                             45.0%   \n",
      "377                          12.3%                             36.5%   \n",
      "380                            NaN                               NaN   \n",
      "\n",
      "    equalRest_winLoss_Win_percent away_winLoss_Win_percent  \\\n",
      "0                           50.0%                    33.3%   \n",
      "1                           77.1%                    65.6%   \n",
      "7                           83.1%                    76.1%   \n",
      "8                           81.7%                    66.3%   \n",
      "9                           74.7%                    60.6%   \n",
      "..                            ...                      ...   \n",
      "374                         37.4%                    24.9%   \n",
      "375                         28.0%                    17.4%   \n",
      "376                         24.4%                    17.4%   \n",
      "377                         19.1%                    11.3%   \n",
      "380                           NaN                      NaN   \n",
      "\n",
      "    home_winLoss_Win_percent neutralSite_winLoss_Win_percent  \\\n",
      "0                        NaN                            0.0%   \n",
      "1                      93.3%                           74.9%   \n",
      "7                      93.2%                           73.4%   \n",
      "8                      91.7%                           80.2%   \n",
      "9                      88.0%                           69.2%   \n",
      "..                       ...                             ...   \n",
      "374                    54.3%                           36.9%   \n",
      "375                    48.3%                           35.5%   \n",
      "376                    44.0%                           28.4%   \n",
      "377                    44.1%                           32.2%   \n",
      "380                      NaN                             NaN   \n",
      "\n",
      "    overallWinPercentage_Win_percent                     Institution Name_x  \\\n",
      "0                              25.0%                                    NaN   \n",
      "1                              80.7%  University of Arkansas at Little Rock   \n",
      "7                              82.8%                     Gonzaga University   \n",
      "8                              81.5%                        Duke University   \n",
      "9                              75.5%                 University of Kentucky   \n",
      "..                               ...                                    ...   \n",
      "374                            37.2%              Delaware State University   \n",
      "375                            32.0%              Kennesaw State University   \n",
      "376                            30.7%              San Jose State University   \n",
      "377                            24.8%               Chicago State University   \n",
      "380                              NaN                                    NaN   \n",
      "\n",
      "    Best_Match_in_Team  Match_Score_in_Team  Survey Year    UNITID    OPE ID  \\\n",
      "0                  NaN                  NaN          NaN       NaN       NaN   \n",
      "1               Kansas                 90.0          NaN       NaN       NaN   \n",
      "7              Gonzaga                 98.0          NaN       NaN       NaN   \n",
      "8                 Duke                 98.0          NaN       NaN       NaN   \n",
      "9             Kentucky                 96.0          NaN       NaN       NaN   \n",
      "..                 ...                  ...          ...       ...       ...   \n",
      "374        Delaware St                 98.0          NaN       NaN       NaN   \n",
      "375        Kennesaw St                 98.0          NaN       NaN       NaN   \n",
      "376        San Jose St                 98.0          NaN       NaN       NaN   \n",
      "377         Chicago St                 98.0          NaN       NaN       NaN   \n",
      "380                NaN                  NaN       2022.0  222178.0  353700.0   \n",
      "\n",
      "               Institution Name_y State CD  Expenses Men's Team  \n",
      "0                             NaN      NaN                  NaN  \n",
      "1                             NaN      NaN                  NaN  \n",
      "7                             NaN      NaN                  NaN  \n",
      "8                             NaN      NaN                  NaN  \n",
      "9                             NaN      NaN                  NaN  \n",
      "..                            ...      ...                  ...  \n",
      "374                           NaN      NaN                  NaN  \n",
      "375                           NaN      NaN                  NaN  \n",
      "376                           NaN      NaN                  NaN  \n",
      "377                           NaN      NaN                  NaN  \n",
      "380  Abilene Christian University       TX            2322034.0  \n",
      "\n",
      "[232 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Merge `bball_expenses` with `result_df` on \"Institution Name\"\n",
    "merged_df = pd.merge(win_percent_df, team_names, left_on=\"Team\", right_on=\"Best_Match_in_Team\", how=\"left\")\n",
    "merged_df = merged_df.drop_duplicates(subset=[\"Institution Name\"])\n",
    "combined_df = pd.merge(merged_df, bball_expenses_2022, left_on=\"Team\", right_on=\"Institution Name\", how=\"outer\")\n",
    "combined_df = combined_df.drop_duplicates(subset=[\"Team\"])\n",
    "\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>afterLoss_winLoss_Win_percent</th>\n",
       "      <th>afterLoss_winLoss_MOV</th>\n",
       "      <th>afterLoss_winLoss_ATS</th>\n",
       "      <th>afterWin_winLoss_Win_percent</th>\n",
       "      <th>afterWin_winLoss_MOV</th>\n",
       "      <th>afterWin_winLoss_ATS</th>\n",
       "      <th>asUnderdog_winLoss_Win_percent</th>\n",
       "      <th>asUnderdog_winLoss_MOV</th>\n",
       "      <th>asUnderdog_winLoss_ATS</th>\n",
       "      <th>...</th>\n",
       "      <th>away_winLoss_ATS</th>\n",
       "      <th>home_winLoss_Win_percent</th>\n",
       "      <th>home_winLoss_MOV</th>\n",
       "      <th>home_winLoss_ATS</th>\n",
       "      <th>neutralSite_winLoss_Win_percent</th>\n",
       "      <th>neutralSite_winLoss_MOV</th>\n",
       "      <th>neutralSite_winLoss_ATS</th>\n",
       "      <th>overallWinPercentage_Win_percent</th>\n",
       "      <th>overallWinPercentage_MOV</th>\n",
       "      <th>overallWinPercentage_ATS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mercyhurst</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>...</td>\n",
       "      <td>7.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>--</td>\n",
       "      <td>25.0%</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>85.2%</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>79.6%</td>\n",
       "      <td>11.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>42.7%</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>93.3%</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>74.9%</td>\n",
       "      <td>9.2</td>\n",
       "      <td>+0.8</td>\n",
       "      <td>80.7%</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gonzaga</td>\n",
       "      <td>82.1%</td>\n",
       "      <td>14.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>82.7%</td>\n",
       "      <td>13.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.5%</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>93.2%</td>\n",
       "      <td>21.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>73.4%</td>\n",
       "      <td>7.3</td>\n",
       "      <td>+0.5</td>\n",
       "      <td>82.8%</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Duke</td>\n",
       "      <td>78.9%</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>81.5%</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>43.3%</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>91.7%</td>\n",
       "      <td>20.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>80.2%</td>\n",
       "      <td>9.7</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>81.5%</td>\n",
       "      <td>13.9</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>72.7%</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>76.1%</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>40.0%</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.0%</td>\n",
       "      <td>15.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.2%</td>\n",
       "      <td>7.0</td>\n",
       "      <td>+0.4</td>\n",
       "      <td>75.5%</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>San Jose St</td>\n",
       "      <td>26.1%</td>\n",
       "      <td>-8.1</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>37.5%</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>17.5%</td>\n",
       "      <td>-11.1</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>44.0%</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>28.4%</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>30.7%</td>\n",
       "      <td>-6.3</td>\n",
       "      <td>-0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>Ark Pine Bl</td>\n",
       "      <td>25.1%</td>\n",
       "      <td>-11.6</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>41.6%</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>12.8%</td>\n",
       "      <td>-15.9</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>47.9%</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>39.6%</td>\n",
       "      <td>-6.3</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>29.2%</td>\n",
       "      <td>-9.9</td>\n",
       "      <td>-0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>Miss Val St</td>\n",
       "      <td>24.0%</td>\n",
       "      <td>-11.9</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>51.2%</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>9.4%</td>\n",
       "      <td>-19.5</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>56.2%</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>31.3%</td>\n",
       "      <td>-7.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.7%</td>\n",
       "      <td>-8.8</td>\n",
       "      <td>-1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>Chicago St</td>\n",
       "      <td>22.3%</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>31.5%</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.3%</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>44.1%</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>32.2%</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>+0.3</td>\n",
       "      <td>24.8%</td>\n",
       "      <td>-10.8</td>\n",
       "      <td>-1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>W Georgia</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0%</td>\n",
       "      <td>-18.8</td>\n",
       "      <td>-4.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Team afterLoss_winLoss_Win_percent  afterLoss_winLoss_MOV  \\\n",
       "0     Mercyhurst                        100.0%                    5.0   \n",
       "1         Kansas                         85.2%                   12.5   \n",
       "2        Gonzaga                         82.1%                   14.9   \n",
       "3           Duke                         78.9%                   13.0   \n",
       "4       Kentucky                         72.7%                    9.3   \n",
       "..           ...                           ...                    ...   \n",
       "359  San Jose St                         26.1%                   -8.1   \n",
       "360  Ark Pine Bl                         25.1%                  -11.6   \n",
       "361  Miss Val St                         24.0%                  -11.9   \n",
       "362   Chicago St                         22.3%                  -12.0   \n",
       "363    W Georgia                          0.0%                  -23.0   \n",
       "\n",
       "     afterLoss_winLoss_ATS afterWin_winLoss_Win_percent  afterWin_winLoss_MOV  \\\n",
       "0                     12.5                          NaN                   NaN   \n",
       "1                      2.3                        79.6%                  11.4   \n",
       "2                      2.0                        82.7%                  13.8   \n",
       "3                      0.8                        81.5%                  13.5   \n",
       "4                      0.6                        76.1%                  10.0   \n",
       "..                     ...                          ...                   ...   \n",
       "359                   -1.3                        37.5%                  -3.5   \n",
       "360                   -0.8                        41.6%                  -3.9   \n",
       "361                   -0.5                        51.2%                   0.2   \n",
       "362                   -1.8                        31.5%                  -7.0   \n",
       "363                    0.5                          NaN                   NaN   \n",
       "\n",
       "     afterWin_winLoss_ATS asUnderdog_winLoss_Win_percent  \\\n",
       "0                     NaN                          50.0%   \n",
       "1                     0.4                          42.7%   \n",
       "2                     1.0                          40.5%   \n",
       "3                     0.3                          43.3%   \n",
       "4                     0.4                          40.0%   \n",
       "..                    ...                            ...   \n",
       "359                  -0.1                          17.5%   \n",
       "360                  -0.9                          12.8%   \n",
       "361                  -1.8                           9.4%   \n",
       "362                   0.0                          12.3%   \n",
       "363                   NaN                           0.0%   \n",
       "\n",
       "     asUnderdog_winLoss_MOV  asUnderdog_winLoss_ATS  ... away_winLoss_ATS  \\\n",
       "0                      -6.0                     7.3  ...              7.3   \n",
       "1                      -3.8                    -0.2  ...             -0.3   \n",
       "2                      -2.7                     2.1  ...              1.3   \n",
       "3                      -1.1                     2.9  ...              0.2   \n",
       "4                      -2.4                     2.0  ...              1.0   \n",
       "..                      ...                     ...  ...              ...   \n",
       "359                   -11.1                    -0.7  ...             -0.7   \n",
       "360                   -15.9                    -1.4  ...             -0.7   \n",
       "361                   -19.5                    -1.2  ...             -2.3   \n",
       "362                   -18.0                    -1.4  ...             -2.0   \n",
       "363                   -29.0                    -4.3  ...             -4.3   \n",
       "\n",
       "     home_winLoss_Win_percent  home_winLoss_MOV home_winLoss_ATS  \\\n",
       "0                         NaN               NaN              NaN   \n",
       "1                       93.3%              18.0              1.3   \n",
       "2                       93.2%              21.9              1.5   \n",
       "3                       91.7%              20.3              1.2   \n",
       "4                       88.0%              15.7              0.0   \n",
       "..                        ...               ...              ...   \n",
       "359                     44.0%              -1.0             -1.2   \n",
       "360                     47.9%               0.8              0.4   \n",
       "361                     56.2%               2.6              1.2   \n",
       "362                     44.1%              -1.1             -1.6   \n",
       "363                       NaN               NaN              NaN   \n",
       "\n",
       "     neutralSite_winLoss_Win_percent  neutralSite_winLoss_MOV  \\\n",
       "0                               0.0%                    -22.0   \n",
       "1                              74.9%                      9.2   \n",
       "2                              73.4%                      7.3   \n",
       "3                              80.2%                      9.7   \n",
       "4                              69.2%                      7.0   \n",
       "..                               ...                      ...   \n",
       "359                            28.4%                     -5.9   \n",
       "360                            39.6%                     -6.3   \n",
       "361                            31.3%                     -7.4   \n",
       "362                            32.2%                     -5.2   \n",
       "363                              NaN                      NaN   \n",
       "\n",
       "    neutralSite_winLoss_ATS  overallWinPercentage_Win_percent  \\\n",
       "0                        --                             25.0%   \n",
       "1                      +0.8                             80.7%   \n",
       "2                      +0.5                             82.8%   \n",
       "3                      -0.3                             81.5%   \n",
       "4                      +0.4                             75.5%   \n",
       "..                      ...                               ...   \n",
       "359                    -1.0                             30.7%   \n",
       "360                    -1.8                             29.2%   \n",
       "361                     0.0                             31.7%   \n",
       "362                    +0.3                             24.8%   \n",
       "363                     NaN                             20.0%   \n",
       "\n",
       "     overallWinPercentage_MOV overallWinPercentage_ATS  \n",
       "0                       -12.8                      7.3  \n",
       "1                        11.8                      0.7  \n",
       "2                        14.2                      1.2  \n",
       "3                        13.9                      0.5  \n",
       "4                        10.1                      0.4  \n",
       "..                        ...                      ...  \n",
       "359                      -6.3                     -0.9  \n",
       "360                      -9.9                     -0.6  \n",
       "361                      -8.8                     -1.2  \n",
       "362                     -10.8                     -1.6  \n",
       "363                     -18.8                     -4.3  \n",
       "\n",
       "[364 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(merged_win_loss_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Buffalo'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [28], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Initialize and train the model\u001b[39;00m\n\u001b[0;32m     23\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m---> 24\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m     27\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_base.py:609\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    605\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    607\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 609\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    618\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:1301\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1296\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1299\u001b[0m     )\n\u001b[1;32m-> 1301\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1320\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:1012\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1012\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1015\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1016\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\_array_api.py:745\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    743\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 745\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py:2064\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2063\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Buffalo'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "for col in merged_win_loss_stats.columns:\n",
    "    if merged_win_loss_stats[col].dtype == object and merged_win_loss_stats[col].str.contains('%').any():\n",
    "        merged_win_loss_stats[col] = merged_win_loss_stats[col].apply(lambda x: float(x.strip('%')) / 100 if isinstance(x, str) else x)\n",
    "\n",
    "X = merged_win_loss_stats.drop(columns=['overallWinPercentage_Win_percent'])\n",
    "y = merged_df['overallWinPercentage_Win_percent']\n",
    "\n",
    "data = pd.concat([X, y], axis = 1)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "X= data.drop(columns=['overallWinPercentage_Win_percent', 'Team'])\n",
    "y= data['overallWinPercentage_Win_percent']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
